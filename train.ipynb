{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea62514d-3063-424c-897f-18d74511ff72",
   "metadata": {},
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from dataset import MyDataset\n",
    "import transforms as T\n",
    "from model import UNet\n",
    "from utils import (\n",
    "    compute_gray,\n",
    "    train_one_epoch,\n",
    "    evaluate,\n",
    "    plot,\n",
    "    plot_lr_decay,\n",
    "    plt_loss_iou\n",
    ")\n",
    "\n",
    "\n",
    "# 训练集预处理\n",
    "class SegmentationPresetTrain:\n",
    "    def __init__(self, base_size=600, rcrop_size=480, hflip_prob=0.5, vflip_prob=0.5, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)):\n",
    "        min_size = int(0.5 * base_size)\n",
    "        max_size = int(1.5 * base_size)\n",
    "\n",
    "        trans = [T.RandomResize(min_size, max_size)]\n",
    "        if hflip_prob > 0:\n",
    "            trans.append(T.RandomHorizontalFlip(hflip_prob))\n",
    "        if vflip_prob > 0:\n",
    "            trans.append(T.RandomVerticalFlip(vflip_prob))\n",
    "        trans.extend([\n",
    "            T.RandomCrop(rcrop_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "        self.transforms = T.Compose(trans)\n",
    "\n",
    "    def __call__(self, img, target):\n",
    "        return self.transforms(img, target)\n",
    "\n",
    "\n",
    "# 测试集预处理\n",
    "class SegmentationPresetTest:\n",
    "    def __init__(self, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)):\n",
    "        self.transforms = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img, target):\n",
    "        return self.transforms(img, target)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using {} device training.\".format(device))\n",
    "\n",
    "    with open('./run_results/train_log_results.txt', \"a\") as f:\n",
    "        info = f\"[train hyper-parameters: {args}]\\n\"\n",
    "        f.write(info)\n",
    "\n",
    "    train_tf = SegmentationPresetTrain(base_size=args.base_size, rcrop_size=args.crop_size)\n",
    "    test_tf = SegmentationPresetTest()\n",
    "\n",
    "    num_classes = compute_gray()\n",
    "\n",
    "    trainDataset = MyDataset(imgs_path='./data/train/images', txt_path='./data/grayList.txt', transform=train_tf)\n",
    "    testDataset = MyDataset(imgs_path='./data/test/images', txt_path='./data/grayList.txt', transform=test_tf)\n",
    "\n",
    "    num_workers = min([os.cpu_count(), args.batch_size if args.batch_size > 1 else 0, 8])\n",
    "    print('Using %g dataloader workers' % num_workers)\n",
    "\n",
    "    trainLoader = DataLoader(trainDataset, batch_size=args.batch_size, num_workers=num_workers, shuffle=True)\n",
    "    testLoader = DataLoader(testDataset, batch_size=1, num_workers=num_workers, shuffle=False)\n",
    "\n",
    "    model = UNet(num_classes=num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-8)\n",
    "\n",
    "    lf_plot = lambda x: ((1 + math.cos(x * math.pi / args.epochs)) / 2) * (1 - args.lrf) + args.lrf\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf_plot)\n",
    "    plot_lr_decay(scheduler, optimizer, args.epochs)\n",
    "\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / args.epochs)) / 2) * (1 - args.lrf) + args.lrf\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "\n",
    "    best_mean_iou = 0.0\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    train_miou_list = []\n",
    "    test_miou_list = []\n",
    "    for epoch in range(args.epochs):\n",
    "        train_loss, test_loss, lr = train_one_epoch(model=model, optim=optimizer, train_loader=trainLoader, test_loader=testLoader, device=device)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        train_miou, test_miou, test_confmat = evaluate(model=model, train_loader=trainLoader, test_loader=testLoader, device=device, num=num_classes)\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "        train_miou_list.append(train_miou)\n",
    "        test_miou_list.append(test_miou)\n",
    "\n",
    "        with open('./run_results/train_log_results.txt', \"a\") as f:\n",
    "            info = f\"[epoch: {epoch+1}]\\n\" + test_confmat + '\\n\\n'\n",
    "            f.write(info)\n",
    "\n",
    "        if test_miou > best_mean_iou:\n",
    "            best_mean_iou = test_miou\n",
    "            torch.save(model.state_dict(), './run_results/best_model.pth')\n",
    "\n",
    "        print(\"[epoch:%d]\" % (epoch + 1))\n",
    "        print(\"learning rate:%.8f\" % lr)\n",
    "        print(\"train loss:%.4f \\t train mean iou:%.4f\" % (train_loss, train_miou))\n",
    "        print(\"test loss:%.4f \\t test mean iou:%.4f\" % (test_loss, test_miou), end='\\n\\n')\n",
    "\n",
    "    plt_loss_iou(train_loss_list, test_loss_list, train_miou_list, test_miou_list)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"unet segmentation\")\n",
    "    parser.add_argument(\"--base-size\", default=400, type=int)\n",
    "    parser.add_argument(\"--crop-size\", default=240, type=int)\n",
    "    parser.add_argument(\"--batch-size\", default=8, type=int)\n",
    "    parser.add_argument(\"--epochs\", default=10, type=int)\n",
    "    parser.add_argument('--lr', default=0.01, type=float)\n",
    "    parser.add_argument('--lrf', default=0.001, type=float)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()  # 允许未知参数\n",
    "    print(args)\n",
    "\n",
    "    if os.path.exists(\"./run_results\"):\n",
    "        shutil.rmtree('./run_results')\n",
    "    os.mkdir(\"./run_results\")\n",
    "\n",
    "    main(args)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e95957-e5b0-4457-9520-4ab5bef1ba77",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
